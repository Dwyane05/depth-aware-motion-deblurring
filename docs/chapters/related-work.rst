The works on motion deblurring can be divided into two basic classes: single image deblurring and multi-image deblurring. Furthermore they can be distinguished into the assumption on blur kernels: spatially uniform and non-uniform.

In single image deblurring Fergus *et al.* :cite:`Fergus2006` proposed a variational Bayesian approach to estimate the blur kernel by maximizing the marginal probability. Levin *et al.* :cite:`Levin2011` suggested an improved efficient marginal likelihood approximation. Several other approaches :cite:`Shan2008`, :cite:`Joshi2008`, :cite:`Cho2009`, :cite:`Xu2010` altered the MAP problem for estimate the latent image and the blur kernel iteratively.

These methods assumes that all the pixels are blurred with the same blur kernel - a uniform kernel. Though blur at a specific position is highly correlated with camera motion and the corresponding scene depth. This results in a spatially non-uniform kernel. Joshi *et al.* :cite:`Joshi2010` discussed the spatial variance of Point Spread Functions (PSFs) which is correlated to rotational and translational camera motion. Whereas the spatial variance caused by rotation is depth independent and that caused by translation depends on scene depth.

Some methods deals with rotation blur models such as Shan *et al.* :cite:`Shan2007` and Whyte *et al.* :cite:`Whyte2010`. However camera translation which causes significant image blur isn't handled in these approaches. Because translation depends on scene depth some works already tried to compute scene depth by stereo approaches. Favaro *et al.* :cite:`Favaro2004` modeled motion-blur and defocus of a scene from a collection of motion-blurred and defocused images as an anisotropic diffusion process. Sorel *et al.* :cite:`Sorel2008` proposed an algorithm that belongs to the group of variational methods that estimate simultaneously a sharp image and a depth map, based on the minimization of a cost functional. It uses multiple blurred images and a user selection of a region of constant depth as input.

